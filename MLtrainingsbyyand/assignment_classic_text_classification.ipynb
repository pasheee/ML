{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jNtLJlW4v5VF"
   },
   "source": [
    "## Классификация текстов\n",
    "\n",
    "В данном задании мы будем работать над задачей классификации последовательностей (текстов) с использованием различных методов векторизации слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "grIwIEWAv5VK"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from IPython import display\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "out_dict = dict()\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "CijSj69Ov5VN"
   },
   "source": [
    "### Предобработка текста и токенизация\n",
    "\n",
    "Предобработка практически аналогична рассмотренной на предшествующем занятии. Библиотека `nltk` [link](https://www.nltk.org) широко используется при обработке текстов. По ссылке выше можно найти ее развернутое описание и документацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: How to be a grown-up at work: replace \"I don't want to do that\" with \"Ok, great!\".\n",
      "after: how to be a grown - up at work : replace \" i don ' t want to do that \" with \" ok , great !\".\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "df = pd.read_csv(\n",
    "    \"https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv\",\n",
    "    delimiter=\"\\t\",\n",
    "    header=None,\n",
    ")\n",
    "texts_train = df[0].values[:5000]\n",
    "y_train = df[1].values[:5000]\n",
    "texts_test = df[0].values[5000:]\n",
    "y_test = df[1].values[5000:]\n",
    "\n",
    "\n",
    "tokenizer = WordPunctTokenizer()\n",
    "preprocess = lambda text: \" \".join(tokenizer.tokenize(text.lower()))\n",
    "\n",
    "text = 'How to be a grown-up at work: replace \"I don\\'t want to do that\" with \"Ok, great!\".'\n",
    "print(\n",
    "    \"before:\",\n",
    "    text,\n",
    ")\n",
    "print(\n",
    "    \"after:\",\n",
    "    preprocess(text),\n",
    ")\n",
    "\n",
    "texts_train = [preprocess(text) for text in texts_train]\n",
    "texts_test = [preprocess(text) for text in texts_test]\n",
    "\n",
    "# Small check that everything is done properly\n",
    "assert (\n",
    "    texts_train[5]\n",
    "    == \"campanella gets the tone just right funny in the middle of sad in the middle of hopeful\"\n",
    ")\n",
    "assert texts_test[74] == \"poetry in motion captured on film\"\n",
    "assert len(texts_test) == len(y_test)\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующие функции помогут вам с визуализацией процесса обучения сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "\n",
    "def plot_train_process(\n",
    "    train_loss, val_loss, train_accuracy, val_accuracy, title_suffix=\"\"\n",
    "):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    axes[0].set_title(\" \".join([\"Loss\", title_suffix]))\n",
    "    axes[0].plot(train_loss, label=\"train\")\n",
    "    axes[0].plot(val_loss, label=\"validation\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].set_title(\" \".join([\"Validation accuracy\", title_suffix]))\n",
    "    axes[1].plot(train_accuracy, label=\"train\")\n",
    "    axes[1].plot(val_accuracy, label=\"validation\")\n",
    "    axes[1].legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_and_save_results(\n",
    "    model, model_name, X_train, X_test, y_train, y_test, out_dict\n",
    "):\n",
    "    for data_name, X, y, model in [\n",
    "        (\"train\", X_train, y_train, model),\n",
    "        (\"test\", X_test, y_test, model),\n",
    "    ]:\n",
    "        if isinstance(model, BaseEstimator):\n",
    "            proba = model.predict_proba(X)[:, 1]\n",
    "        elif isinstance(model, nn.Module):\n",
    "            proba = model(X).detach().cpu().numpy()[:, 1]\n",
    "        else:\n",
    "            raise ValueError(\"Unrecognized model type\")\n",
    "\n",
    "        auc = roc_auc_score(y, proba)\n",
    "\n",
    "        out_dict[f\"{model_name}_{data_name}\"] = auc\n",
    "        plt.plot(*roc_curve(y, proba)[:2], label=\"{} AUC={:.4f}\".format(data_name, auc))\n",
    "\n",
    "    plt.plot(\n",
    "        [0, 1],\n",
    "        [0, 1],\n",
    "        \"--\",\n",
    "        color=\"black\",\n",
    "    )\n",
    "    plt.legend(fontsize=\"large\")\n",
    "    plt.title(model_name)\n",
    "    plt.grid()\n",
    "    return out_dict\n",
    "\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Повторение: основные понятия в глубоком обучении\n",
    "\n",
    "__Слой (layer)__ – некоторое преобразование над исходными данными. Простейший пример: линейный слой, являющийся линейным преобразованием над входящими данными (т.е. просто преобразование $WX +b$, как и в линейной регрессии).\n",
    "\n",
    "__Функция активации (activation function)__ – нелинейное преобразование, применяется ко всем данным пришедшим на вход поэлементно. Благодаря функциям активации нейронные сети делают *нелинейные преобразования* над исходными признаками, тем самым порождая более информативное признаковое описание.\n",
    "\n",
    "__Нейронная сеть (neural network)__ – композиция линейных и нелинейных преобразований (как правило, представимая в виде последовательности слоев и функций активации). Изучением нейронных сетей и их применимости в различных задачах занимается глубокое обучение (Deep Learning). В большинстве случаев вся нейронная сеть является одной сложной *дифференцируемой* функцией, что накладывает ограничения на возможность использование тех или иных преобразований.\n",
    "\n",
    "__Регуляризация (regularization)__ – механизм наложения ограничений на решение в зависимости от экспертных знаний и/или априорных предположений о решаемой задаче. Может быть представлена в форме дополнительного члена в функции потерь (например, $L1$ или $L2$ регуляризация), в форме ограничений на структуру модели (`Dropout`, `Batch Normalization`) и в других формах.\n",
    "\n",
    "__Функция потерь (loss function)__ – функция потерь, оценивающая качество полученного предсказания. Как правило, от функции потерь требуется свойство дифференцируемости (т.к. настройка параметров сети происходит методом *обратного распространения ошибки*). В некоторых случаях (например, в обучении с подкреплением) используются и недифференцируемые функции потерь/награды. Их использование требует доработки механизма обучения нейронных сетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Работа с текстами и последовательностями\n",
    "\n",
    "* __Последовательности__. Данные – наборы значений, на которых задано отношение порядка. Значения могут быть дискретными (например, ДНК), или же могут принимать значения из непрерывного интервала (временной ряд энергопотребления дата центра). Перестановка значений приводит к потере информации. Нельзя нарушать отношение порядка (тестирование на прошлом, обучение на будущем).\n",
    "\n",
    "* __Тексты__. Данные – наборы слов/символов. По факту являются последовательностями значений из конечного алфавита, но обладают достаточно строгой внутренней структурой ввиду существования грамматики.\n",
    "\n",
    "В работе с естественным языком (в виде текста в первую очередь), а также в работе с последовательностями себя отлично зарекомендовали рекуррентные сети и сети, основанные на механизме внимания (attention mechanism), подобные модели Transformer, предложенной в 2017 году в работе Attention is all you need. Как рекуррентные, так и transformer-like модели учитывают зависимость элементов последовательности друг от друга (и в целом наличие порядка), что позволяет им порождать информативные признаковые представления автоматически (подобно сверточным сетям при работе с изображениями). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wgd0Mlzsv5VO"
   },
   "source": [
    "### Задача №1. Мешок слов.\n",
    "\n",
    "Воспользуйтесь классическим подходом к векторизации текстов: мешком слов. Для этого вы можете как воспользоваться `CountVectorizer` из `sklearn`, так и самостоятельно реализованный вариант.\n",
    "\n",
    "Мешок слов сопоставляет каждому слову из словаря уникальный индекс (номер слова в словаре) и строит итоговый вектор для текста как набор счетчиков каждого слова из словаря. Этот подход эквивалентен построению суммы `one-hot` векторов для каждого из слов в тексте.\n",
    "\n",
    "#### __One-hot кодирование__. \n",
    "Каждому слову в языке можно сопоставить уникальный индекс и поставить слову в соответствие вектор, где нули стоят на всех местах, кроме заданного индекса. Такой подход называется one-hot кодированием. Пример такого кодирования можно увидеть ниже.\n",
    "\n",
    "*Пример: слово \"собака\" находится на третьем месте в словаре из 5 слов. Тогда ему будет соответствовать вектор `[0, 0, 1, 0, 0]`. Слово \"кошка\" стоит на втором месте, ему соответствует вектор `[0, 1, 0, 0, 0]`. Слово \"кот\" – на четвёртом, ему соответствует вектор `[0, 0, 0, 1, 0]`.*\n",
    "\n",
    "\n",
    "\n",
    "Обращаем ваше внимание, в части 1 используется лишь `k` наиболее часто встречаемых слов из обучающей части выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZNHFsVuPv5VP",
    "outputId": "55ed5eb3-7442-40ae-accd-5dc595335321"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "k = min(10000, len(set(\" \".join(texts_train).split())))\n",
    "\n",
    "counts = Counter(\" \".join(texts_train).split())\n",
    "\n",
    "bow_vocabulary = [key for key, val in counts.most_common(k)]\n",
    "\n",
    "\n",
    "def text_to_bow(text):\n",
    "    \"\"\"convert text string to an array of token counts. Use bow_vocabulary.\"\"\"\n",
    "    sent_vec = np.zeros(len(bow_vocabulary))\n",
    "    counts = Counter(text.split())\n",
    "    for i, token in enumerate(bow_vocabulary):\n",
    "        if token in counts:\n",
    "            sent_vec[i] = counts[token]\n",
    "    return np.array(sent_vec, \"float32\")\n",
    "\n",
    "\n",
    "X_train_bow = np.stack(list(map(text_to_bow, texts_train)))\n",
    "X_test_bow = np.stack(list(map(text_to_bow, texts_test)))\n",
    "\n",
    "# Small check that everything is done properly if you are using local bow implementation\n",
    "k_max = len(set(\" \".join(texts_train).split()))\n",
    "assert X_train_bow.shape == (len(texts_train), min(k, k_max))\n",
    "assert X_test_bow.shape == (len(texts_test), min(k, k_max))\n",
    "assert np.all(\n",
    "    X_train_bow[5:10].sum(-1) == np.array([len(s.split()) for s in texts_train[5:10]])\n",
    ")\n",
    "assert len(bow_vocabulary) <= min(k, k_max)\n",
    "assert X_train_bow[65, bow_vocabulary.index(\"!\")] == texts_train[65].split().count(\"!\")\n",
    "\n",
    "\n",
    "bow_model = LogisticRegression(max_iter=1500).fit(X_train_bow, y_train)\n",
    "\n",
    "out_dict = visualize_and_save_results(\n",
    "    bow_model, \"bow_log_reg_sklearn\", X_train_bow, X_test_bow, y_train, y_test, out_dict\n",
    ")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gSg1inPqv5VR"
   },
   "source": [
    "Результаты неплохие, но явно видно переобучение. Этот вывод можно сделать судя по значительному превосходству качества (AUC ROC) на train выборке относительно test. Более того, на обучающей выборке качество стремится к единице, в то время как на отложенной – значительно ниже, т.е. модель уловила множество зависимостей, свойственных лишь обучающей выборке. Базово проблема переобучения рассматривалась в предыдущих занятиях и еще не раз встретится на курсе в дальнейшем.\n",
    "\n",
    "В данной задаче с переобучением мы разберемся в дальнейшем. Сейчас же реализуйте решение на основе логистической регрессии, но уже используя PyTorch. В результате вам должна быть доступна обученная модель, предсказывающая вероятности для двух классов. Качество на тестовой выборке должно не уступать логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mylogreg(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(Mylogreg, self).__init__()\n",
    "        self.linear = nn.Linear(num_features, 2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.linear(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "HLx_3tOCv5VR"
   },
   "source": [
    "Не забывайте о функциях потерь: `nn.CrossEntropyLoss` объединяет в себе `LogSoftMax` и `NLLLoss`. Также не забывайте о необходимости перенести тензоры на используемый `device`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "W7dcCGLsv5VS"
   },
   "outputs": [],
   "source": [
    "model = Mylogreg(X_train_bow.shape[-1]).to(torch.device('cuda'))\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "CK7iew17v5VS"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "X_train_bow_torch = torch.tensor(X_train_bow, dtype = torch.float).to(device)\n",
    "X_test_bow_torch = torch.tensor(X_test_bow, dtype = torch.float).to(device)\n",
    "\n",
    "y_train_torch = torch.tensor(y_train).to(device)\n",
    "y_test_torch = torch.tensor(y_test).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 10000])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bow_torch.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция ниже поможет с обучением модели. Часть кода необходимо реализовать самостоятельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "K4GGcyXYv5VT"
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    optimizer,\n",
    "    X_train_torch,\n",
    "    y_train_torch,\n",
    "    X_val_torch,\n",
    "    y_val_torch,\n",
    "    n_iterations=500,\n",
    "    batch_size=32,\n",
    "    show_plots=True,\n",
    "    eval_every=50\n",
    "):\n",
    "    train_loss_history = []\n",
    "    train_acc_history = []\n",
    "    val_loss_history = []\n",
    "    val_acc_history = []\n",
    "\n",
    "    local_train_loss_history = []\n",
    "    local_train_acc_history = []\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        # sample batch_size random observations\n",
    "        ix = np.random.randint(0, len(X_train_torch), batch_size)\n",
    "        x_batch = X_train_torch[ix]\n",
    "        y_batch = y_train_torch[ix]\n",
    "\n",
    "        # predict probabilities\n",
    "        y_predicted = model(x_batch)\n",
    "        \n",
    "        # compute loss\n",
    "        loss = loss_function(y_predicted.squeeze(), y_batch)\n",
    "\n",
    "        # compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Adam step\n",
    "        optimizer.step()\n",
    "\n",
    "        # clear gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        local_train_loss_history.append(loss.item())\n",
    "        local_train_acc_history.append(\n",
    "            accuracy_score(\n",
    "                y_batch.to('cpu').detach().numpy(),\n",
    "                (y_predicted.squeeze().to('cpu').detach().numpy() > 0.5).astype(int)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if i % eval_every == 0:\n",
    "            train_loss_history.append(np.mean(local_train_loss_history))\n",
    "            train_acc_history.append(np.mean(local_train_acc_history))\n",
    "            local_train_loss_history, local_train_acc_history = [], []\n",
    "\n",
    "            predictions_val = model(X_val_torch)\n",
    "            val_loss_history.append(loss_function(predictions_val.squeeze(), y_val_torch).to('cpu').detach().item())\n",
    "\n",
    "            acc_score_val = accuracy_score(\n",
    "                y_val_torch.cpu().numpy(),\n",
    "                (predictions_val.squeeze().to('cpu').detach().numpy() > 0.5).astype(int)\n",
    "            )\n",
    "            val_acc_history.append(acc_score_val)\n",
    "\n",
    "            if show_plots:\n",
    "                display.clear_output(wait=True)\n",
    "                plot_train_process(train_loss_history, val_loss_history, train_acc_history, val_acc_history)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "id": "TILA0_Aiv5VU",
    "outputId": "0bb9db5b-82d8-486b-b320-6021d4f37459"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bow_nn_model \u001b[38;5;241m=\u001b[39m train_model(\n\u001b[1;32m      2\u001b[0m     model,\n\u001b[1;32m      3\u001b[0m     optimizer,\n\u001b[1;32m      4\u001b[0m     X_train_bow_torch,\n\u001b[1;32m      5\u001b[0m     y_train_torch,\n\u001b[1;32m      6\u001b[0m     X_test_bow_torch,\n\u001b[1;32m      7\u001b[0m     y_test_torch,\n\u001b[1;32m      8\u001b[0m     n_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3000\u001b[39m,\n\u001b[1;32m      9\u001b[0m )\n",
      "Cell \u001b[0;32mIn[19], line 44\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, X_train_torch, y_train_torch, X_val_torch, y_val_torch, n_iterations, batch_size, show_plots, eval_every)\u001b[0m\n\u001b[1;32m     40\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     42\u001b[0m local_train_loss_history\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     43\u001b[0m local_train_acc_history\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m---> 44\u001b[0m     accuracy_score(\n\u001b[1;32m     45\u001b[0m         y_batch\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(),\n\u001b[1;32m     46\u001b[0m         (y_predicted\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     47\u001b[0m     )\n\u001b[1;32m     48\u001b[0m )\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m eval_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     51\u001b[0m     train_loss_history\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(local_train_loss_history))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:231\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    229\u001b[0m xp, _, device \u001b[38;5;241m=\u001b[39m get_namespace_and_device(y_true, y_pred, sample_weight)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    232\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:112\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    109\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    114\u001b[0m             type_true, type_pred\n\u001b[1;32m    115\u001b[0m         )\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    119\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "bow_nn_model = train_model(\n",
    "    model,\n",
    "    optimizer,\n",
    "    X_train_bow_torch,\n",
    "    y_train_torch,\n",
    "    X_test_bow_torch,\n",
    "    y_test_torch,\n",
    "    n_iterations=3000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "out_dict = visualize_and_save_results(\n",
    "    bow_nn_model,\n",
    "    \"bow_nn_torch\",\n",
    "    X_train_bow_torch,\n",
    "    X_test_bow_torch,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    out_dict,\n",
    ")\n",
    "\n",
    "assert (\n",
    "    out_dict[\"bow_log_reg_sklearn_test\"] - out_dict[\"bow_nn_torch_test\"] < 0.01\n",
    "), \"AUC ROC on test data should be close to the sklearn implementation\"\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEt4byBxv5VU"
   },
   "source": [
    "А теперь повторите процедуру обучения выше, но для различных значений `k` – размера словаря. В список results сохраните `AUC ROC` на тестовой части выборки для модели, обученной со словарем размера `k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(k):\n",
    "    counts = Counter(\" \".join(texts_train).split())\n",
    "    \n",
    "    bow_vocabulary = [key for key, val in counts.most_common(k)]\n",
    "    \n",
    "    \n",
    "    def text_to_bow(text):\n",
    "        \"\"\"convert text string to an array of token counts. Use bow_vocabulary.\"\"\"\n",
    "        sent_vec = np.zeros(len(bow_vocabulary))\n",
    "        counts = Counter(text.split())\n",
    "        for i, token in enumerate(bow_vocabulary):\n",
    "            if token in counts:\n",
    "                sent_vec[i] = counts[token]\n",
    "        return np.array(sent_vec, \"float32\")\n",
    "    \n",
    "    \n",
    "    X_train_bow = np.stack(list(map(text_to_bow, texts_train)))\n",
    "    X_test_bow = np.stack(list(map(text_to_bow, texts_test)))\n",
    "    X_train_bow_torch = torch.tensor(X_train_bow, dtype = torch.float).to(device)\n",
    "    X_test_bow_torch = torch.tensor(X_test_bow, dtype = torch.float).to(device)\n",
    "    \n",
    "    return X_train_bow_torch, X_test_bow_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "jq9qxODpv5VU",
    "outputId": "47cf61ce-533c-46f7-b0c5-6f6f670018cb"
   },
   "outputs": [],
   "source": [
    "vocab_sizes_list = np.arange(100, 5800, 700)\n",
    "results = []\n",
    "softmax = nn.Softmax()\n",
    "for k in vocab_sizes_list:\n",
    "    # data\n",
    "    X_train_bow_torch, X_test_bow_torch = get_train_test_data(k)\n",
    "    y_train_torch = torch.tensor(y_train).to(device)\n",
    "    y_test_torch = torch.tensor(y_test).to(device)\n",
    "    \n",
    "    \n",
    "    model = Mylogreg(X_train_bow_torch.shape[-1]).to(torch.device('cuda'))\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    model = train_model(\n",
    "    model,\n",
    "    optimizer,\n",
    "    X_train_bow_torch,\n",
    "    y_train_torch,\n",
    "    X_test_bow_torch,\n",
    "    y_test_torch,\n",
    "    n_iterations=3000,\n",
    "    )\n",
    "\n",
    "    \n",
    "    \n",
    "    predicted_probas_on_test_for_k_sized_dict = softmax(model(X_test_bow_torch)).to(torch.device('cpu')).detach().numpy()[:, 1]\n",
    "    \n",
    "    assert predicted_probas_on_test_for_k_sized_dict is not None\n",
    "    auc = roc_auc_score(y_test, predicted_probas_on_test_for_k_sized_dict)\n",
    "    results.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert len(results) == len(vocab_sizes_list), \"Check the code above\"\n",
    "assert min(results) >= 0.65, \"Seems like the model is not trained well enough\"\n",
    "assert results[-1] > 0.84, \"Best AUC ROC should not be lower than 0.84\"\n",
    "\n",
    "plt.plot(vocab_sizes_list, results)\n",
    "plt.xlabel(\"num of tokens\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.grid()\n",
    "\n",
    "out_dict[\"bow_k_vary\"] = results\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "iA_3nEyHv5VV"
   },
   "source": [
    "### Задача №2: Использование TF-iDF признаков.\n",
    "\n",
    "Для векторизации текстов также можно воспользоваться TF-iDF. Это позволяет исключить из рассмотрения многие слова, не оказывающие значимого влияния при оценке непохожести текстов.\n",
    "\n",
    "Подробнее про TF-iDF можно почитать, например, [здесь](https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-world-dataset-796d339a4089).\n",
    "Там же можно почитать о его самостоятельной реализации.\n",
    "\n",
    "Ваша задача: векторизовать тексты используя TF-iDF (или `TfidfVectorizer` из `sklearn`, или реализовав его самостоятельно) и построить классификатор с помощью PyTorch, аналогичный задаче №1.\n",
    "\n",
    "Затем также оцените качество классификации по AUC ROC для различных размеров словаря.\n",
    "\n",
    "Качество классификации должно быть не ниже 0.86 AUC ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "THMktAtZNAqP"
   },
   "outputs": [],
   "source": [
    "X_train_tfidf = # your code here\n",
    "X_test_tfidf = # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xHbOlK1dyws8",
    "outputId": "d19d123a-9232-4df5-b743-29e2181144d2"
   },
   "outputs": [],
   "source": [
    "model = # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "id": "fioSJacvjr2v",
    "outputId": "d5b10947-9ee2-48d9-f553-7dfd9871ec20"
   },
   "outputs": [],
   "source": [
    "loss_function = # your code here\n",
    "opt = # your code here\n",
    "\n",
    "model_tf_idf = train_model(model, opt, X_train_tfidf_torch, y_train_torch, X_test_tfidf_torch, y_test_torch, n_iterations=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "out_dict = visualize_and_save_results(\n",
    "    model_tf_idf,\n",
    "    \"tf_idf_nn_torch\",\n",
    "    X_train_tfidf_torch,\n",
    "    X_test_tfidf_torch,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    out_dict,\n",
    ")\n",
    "\n",
    "assert (\n",
    "    out_dict[\"tf_idf_nn_torch_test\"] >= out_dict[\"bow_nn_torch_test\"]\n",
    "), \"AUC ROC on test data should be better or close to BoW for TF-iDF features\"\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично задаче №1 повторите процедуру обучения для различных значений `k` – размера словаря и сохраните `AUC ROC` на тестовой части выборки в список `results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sizes_list = np.arange(100, 5800, 700)\n",
    "results = []\n",
    "\n",
    "for k in vocab_sizes_list:\n",
    "    # your code here\n",
    "    predicted_probas_on_test_for_k_sized_dict = None\n",
    "    assert predicted_probas_on_test_for_k_sized_dict is not None\n",
    "    auc = roc_auc_score(y_test, predicted_probas_on_test_for_k_sized_dict)\n",
    "    results.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert len(results) == len(vocab_sizes_list), \"Check the code above\"\n",
    "assert min(results) >= 0.65, \"Seems like the model is not trained well enough\"\n",
    "assert results[-1] > 0.85, \"Best AUC ROC for TF-iDF should not be lower than 0.84\"\n",
    "\n",
    "plt.plot(vocab_sizes_list, results)\n",
    "plt.xlabel(\"num of tokens\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.grid()\n",
    "\n",
    "out_dict[\"tf_idf_k_vary\"] = results\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Uo-aLAItv5VW"
   },
   "source": [
    "### Задача №3: Сравнение с Наивным Байесовским классификатором.\n",
    "\n",
    "Классические модели все еще способны показать хороший результат во многих задачах. Обучите наивный байесовский классификатор на текстах, векторизованных с помощью BoW и TF-iDF и сравните результаты с моделями выше.\n",
    "\n",
    "*Комментарий: обращаем ваше внимание, необходимо выбрать подходящее к данной задаче априорное распределение для признаков, т.е. выбрать верную версию классификатора из `sklearn`: `GaussianNB`, `MultinomialNB`, `ComplementNB`, `BernoulliNB`, `CategoricalNB`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "f5Hy-mJnW5Hc",
    "outputId": "e1ebb8e4-cec1-4d49-bc9b-28eff714ea78"
   },
   "outputs": [],
   "source": [
    "clf_nb_bow = # your code here\n",
    "\n",
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "out_dict = visualize_and_save_results(clf_nb_bow, 'bow_nb_sklearn', X_train_bow, X_test_bow, y_train, y_test, out_dict)\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nb_tfidf = # your code here\n",
    "\n",
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "out_dict = visualize_and_save_results(clf_nb_tfidf, 'tf_idf_nb_sklearn', X_train_tfidf, X_test_tfidf, y_train, y_test, out_dict)\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert (\n",
    "    out_dict[\"tf_idf_nb_sklearn_test\"] > out_dict[\"bow_nb_sklearn_test\"]\n",
    "), \" TF-iDF results should be better\"\n",
    "assert (\n",
    "    out_dict[\"tf_idf_nb_sklearn_test\"] > 0.86\n",
    "), \"TF-iDF Naive Bayes score should be above 0.86\"\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "tvqsaoedv5VW"
   },
   "source": [
    "### Задача №4: Использование предобученных эмбеддингов\n",
    "#### __Построение эмбеддингов с помощью word2vec__.\n",
    "Предложенные выше подходы обладают существенными недостатками: они не учитывает смысл слов при сопоставлении вектора каждому из них. Поэтому расстояние между one-hot векторами для слов \"кошка\" и \"собака\", для слов \"кошка\" и \"самолет\" или для слов \"кошка\" и \"кот\" будет одинаковой. Для владеющего языком человека разница между словами очевидна, как и то, что \"кошка\" и \"кот\" гораздо ближе друг к другу по смыслу, чем \"кошка\" и \"самолет\". При построении информативного векторного представления также хотелось бы установить смысловую близость слов.\n",
    "\n",
    "С этим может помочь простая мысль (озвученная в различных формах множество раз): __слово в значительной мере определяется контекстом, в котором оно встречается__. На основании чего можно сделать простой вывод: для некоторых слов более характерен один контекст, а для других – другой. Именно на этой идее и построен word2vec (как и многие другие эмбеддинги).\n",
    "\n",
    "По слову можно научиться предсказывать контекст, в котором оно встречается. Конечно, результат не будет идеально точным. Но если модель делает предсказания лучше, чем случайным образом, значит, она улавливает какую-то связь. И тогда внутреннее представление модели для каждого слова и может использоваться в качестве искомого векторного представления, причем и в других задачах.\n",
    "\n",
    "\n",
    "Формулировка гипотезы выше (слово значительно связано с контекстом) позволяет использовать в качестве обучающей выборки все множество текстов для выбранного языка. Собрание сочинений классиков, статьи в энциклопедии, новостные заметки – все это становится обучающей выборкой. И векторные представления, полученные на основе данных текстов позволяют улавливать связь между этими словами.\n",
    "![](https://ruder.io/content/images/size/w2000/2016/04/word_embeddings_colah.png)\n",
    "*Image source: https://ruder.io/word-embeddings-1/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной части для получения предобученных векторных представлений  мы воспользуемся предобученными эмбеддингами из библиотеки `gensim`. В нем доступно несколько эмбеддингов, предобученных на различных корпусах текстов. Полный список можно найти [здесь](https://radimrehurek.com/gensim/models/word2vec.html#pretrained-models). Напоминаем, что лучше использовать те эмбеддинги, которые были обучены на текстах похожей структуры.\n",
    "\n",
    "Ваша задача: обучить модель (достаточно логистической регрессии или же двуслойной неронной сети), используя усредненный эмбеддинг для всех токенов в отзыве, добиться качества не хуже, чем с помощью BoW/TF-iDF и снизить степень переобучения (разницу между AUC ROC на обучающей и тестовой выборках)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DP5td5Ivv5VW",
    "outputId": "8278e048-9676-4ba2-d76b-608f2b321bad"
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "gensim_embedding_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "sC8wyIqY6Ce9"
   },
   "outputs": [],
   "source": [
    "def text_to_average_embedding(text, gensim_embedding_model):\n",
    "    # Разбиваем текст на слова\n",
    "    words = text.lower().split()\n",
    "    # Инициализируем вектор нулями\n",
    "    embedding = np.zeros(gensim_embedding_model.vector_size)\n",
    "    count = 0\n",
    "    \n",
    "    # Для каждого слова\n",
    "    for word in words:\n",
    "        try:\n",
    "            # Если слово есть в модели, добавляем его вектор\n",
    "            embedding += gensim_embedding_model[word]\n",
    "            count += 1\n",
    "        except KeyError:\n",
    "            # Пропускаем слова, которых нет в словаре модели\n",
    "            continue\n",
    "            \n",
    "    # Если нашли хотя бы одно слово, усредняем\n",
    "    if count > 0:\n",
    "        embedding /= count\n",
    "        \n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "yZ8-03TIJNjz"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gensim_embedding_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m X_train_emb \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m----> 2\u001b[0m     text_to_average_embedding(text, gensim_embedding_model) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts_train\n\u001b[1;32m      3\u001b[0m ]\n\u001b[1;32m      4\u001b[0m X_test_emb \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m     text_to_average_embedding(text, gensim_embedding_model) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts_test\n\u001b[1;32m      6\u001b[0m ]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mlen\u001b[39m(X_train_emb[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m==\u001b[39m gensim_embedding_model\u001b[38;5;241m.\u001b[39mvector_size\n\u001b[1;32m     10\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeems like the embedding shape is wrong\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gensim_embedding_model' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_emb = [\n",
    "    text_to_average_embedding(text, gensim_embedding_model) for text in texts_train\n",
    "]\n",
    "X_test_emb = [\n",
    "    text_to_average_embedding(text, gensim_embedding_model) for text in texts_test\n",
    "]\n",
    "\n",
    "assert (\n",
    "    len(X_train_emb[0]) == gensim_embedding_model.vector_size\n",
    "), \"Seems like the embedding shape is wrong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "3Gw5B5JJ7Z1y"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_emb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m X_train_emb_torch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(X_train_emb)\n\u001b[1;32m      4\u001b[0m X_test_emb_torch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(X_test_emb)\n\u001b[1;32m      5\u001b[0m y_train_torch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_emb' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "X_train_emb_torch = torch.FloatTensor(X_train_emb)\n",
    "X_test_emb_torch = torch.FloatTensor(X_test_emb)\n",
    "y_train_torch = torch.FloatTensor(y_train)\n",
    "y_test_torch = torch.FloatTensor(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.layer1 = torch.nn.Linear(input_size, 64)\n",
    "        self.layer2 = torch.nn.Linear(64, 1)\n",
    "        self.relu = torch.nn.Tanh()\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        # x = self.dropout(x)\n",
    "        x = self.layer2(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "model = SimpleNN(gensim_embedding_model.vector_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "id": "IP-Be_CRHI1f",
    "outputId": "9f6b1aca-a550-48c1-b041-29d43c239138"
   },
   "outputs": [],
   "source": [
    "loss_function = torch.nn.BCELoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model = train_model(model, opt, X_train_emb_torch, y_train_torch, X_test_emb_torch, y_test_torch, n_iterations=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_and_save_results(\n",
    "    model, model_name, X_train, X_test, y_train, y_test, out_dict\n",
    "):\n",
    "    for data_name, X, y in [(\"train\", X_train, y_train), (\"test\", X_test, y_test)]:\n",
    "        # Получение вероятностей\n",
    "        proba = model(X).detach().cpu().numpy()[:, 0]\n",
    "\n",
    "        # Вычисление AUC\n",
    "        auc = roc_auc_score(y, proba)\n",
    "\n",
    "        out_dict[f\"{model_name}_{data_name}\"] = auc\n",
    "        plt.plot(*roc_curve(y, proba)[:2], label=\"{} AUC={:.4f}\".format(data_name, auc))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"--\", color=\"black\")\n",
    "    plt.legend(fontsize=\"large\")\n",
    "    plt.title(model_name)\n",
    "    plt.grid()\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "out_dict = visualize_and_save_results(\n",
    "    model,\n",
    "    \"emb_nn_torch\",\n",
    "    X_train_emb_torch,\n",
    "    X_test_emb_torch,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    out_dict,\n",
    ")\n",
    "assert (\n",
    "    out_dict[\"emb_nn_torch_test\"] > 0.87\n",
    "), \"AUC ROC on test data should be better than 0.86\"\n",
    "assert (\n",
    "    out_dict[\"emb_nn_torch_train\"] - out_dict[\"emb_nn_torch_test\"] < 0.1\n",
    "), \"AUC ROC on test and train data should not be different more than by 0.1\"\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict[\"emb_nn_torch_test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы:\n",
    "_Сформулируйте выводы о каждом из подходов к векторизации слов, а также о работоспособности моделей (Naive Bayes, Logistic Regression, etc.)_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "hohtOwysavfv"
   },
   "source": [
    "### Сдача задания\n",
    "Запустите код ниже для генерации посылки и сдайте на проверку в контест файл `submission_dict_hw_text_classification.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o-lidlX4a_mM"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "FILENAME = \"submission_dict_hw_text_classification.json\"\n",
    "with open(FILENAME, \"w\") as iofile:\n",
    "    json.dump(out_dict, iofile)\n",
    "print(f\"File saved to `{FILENAME}`\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_hw01_texts.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
