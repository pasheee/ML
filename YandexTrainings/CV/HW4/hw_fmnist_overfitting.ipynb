{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDsVMGiVgSq2"
   },
   "source": [
    "## Переобучение нейронных сетей и борьба с ним\n",
    "\n",
    "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/girafe_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3isBRG6PgSq6"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "def args_and_kwargs(*args, **kwargs):\n",
    "    return args, kwargs\n",
    "\n",
    "def parse_pytorch_model(model_str):\n",
    "    def parse_layer(layer_str):\n",
    "        layer_name, params = layer_str.split(\"(\", 1)\n",
    "        layer_info = {\"type\": layer_name.strip()}\n",
    "        params_template = layer_str.replace(layer_name, \"args_and_kwargs\")\n",
    "        \n",
    "        param_dict = {}\n",
    "        if len(params):\n",
    "            args, kwargs = eval(params_template)\n",
    "            if len(args) or len(kwargs):\n",
    "                param_dict[\"args\"] = args\n",
    "                for name, value in kwargs.items():\n",
    "                    param_dict[name] = value\n",
    "        layer_info[\"parameters\"] = param_dict\n",
    "        return layer_info\n",
    "\n",
    "    model_dict = {}\n",
    "    lines = model_str.splitlines()\n",
    "    model_name = lines[0].strip(\"()\")\n",
    "    model_dict[\"model_name\"] = model_name\n",
    "    model_dict[\"layers\"] = []\n",
    "\n",
    "    layer_regex = re.compile(r\"\\((\\d+)\\): (.+)\")\n",
    "    for line in lines[1:]:\n",
    "        line = line.strip()\n",
    "        match = layer_regex.match(line)\n",
    "        if match:\n",
    "            index, layer = match.groups()\n",
    "            model_dict[\"layers\"].append({\"index\": int(index), \"layer\": parse_layer(layer)})\n",
    "    return model_dict\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "def get_predictions(model, eval_data, step=10):\n",
    "\n",
    "    predicted_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx in range(0, len(eval_data), step):\n",
    "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
    "\n",
    "    predicted_labels = torch.cat(predicted_labels)\n",
    "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
    "    return predicted_labels\n",
    "\n",
    "\n",
    "def get_accuracy(model, data_loader):\n",
    "    predicted_labels = []\n",
    "    real_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            y_predicted = model(batch[0].to(device))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
    "            real_labels.append(batch[1])\n",
    "\n",
    "    predicted_labels = torch.cat(predicted_labels)\n",
    "    real_labels = torch.cat(real_labels)\n",
    "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
    "    return accuracy_score\n",
    "\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_overfitting_data_dict.npy\"\n",
    "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zeA6Q5-CgSq7"
   },
   "source": [
    "### Задача №1 (уже решённая): Создание и обучение модели (Separation)\n",
    "Вы уже решали эту задачу ранее, так что сейчас просто воспроизведите своё решение. Оно понадобится вам в дальнейших шагах.\n",
    "__Ваша первая задача всё та же: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_DEVICE_ID = 0  # change if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nPG1KbQAgl8b"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "device = (\n",
    "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    ")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "id": "aYcL28OsgSq8",
    "outputId": "93aafa07-fb56-43bd-f928-918f45fe30e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Image label: 4')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "train_fmnist_data = FashionMNIST(\n",
    "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "test_fmnist_data = FashionMNIST(\n",
    "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "random_batch = next(iter(train_data_loader))\n",
    "_image, _label = random_batch[0][0], random_batch[1][0]\n",
    "plt.figure()\n",
    "plt.imshow(_image.reshape(28, 28))\n",
    "plt.title(f\"Image label: {_label}\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6jWRv1rgSq8"
   },
   "source": [
    "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
    "\n",
    "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CV_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv2d(1, 32, 5)\n",
    "        self.norm1 = nn.BatchNorm2d(32)\n",
    "        self.c2 = nn.Conv2d(32, 64, 3)\n",
    "        self.norm2 = nn.BatchNorm2d(64)\n",
    "        self.c3 = nn.Conv2d(64, 128, 3)\n",
    "        self.norm3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.pooling = nn.MaxPool2d(2)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "        self.conv_non_lin = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.l1 = nn.Linear(128 * 10 * 10, 512)\n",
    "        self.l2 = nn.Linear(512, 124)\n",
    "        self.projection = nn.Linear(124, 10)\n",
    "        self.non_lin = nn.Tanh()\n",
    "\n",
    "    def forward(self, X):\n",
    "        conv_out = self.conv_non_lin( self.norm2( self.c2( self.norm1( self.conv_non_lin(self.c1(X)) )  ) ) )\n",
    "        conv_out = self.conv_non_lin( self.pooling( self.c3(conv_out) ) )\n",
    "        flattened_conv_out = self.flatten(conv_out)\n",
    "\n",
    "        return self.projection( self.non_lin( self.l2( self.non_lin(self.dropout(self.l1(flattened_conv_out))) ) ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "BcyEFX-RgSq8"
   },
   "outputs": [],
   "source": [
    "# Creating model instance\n",
    "model_task_1 = CV_Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAoLV4dkoy5M"
   },
   "source": [
    "Не забудьте перенести модель на выбранный `device`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Xas9SIXDoxvZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CV_Model(\n",
       "  (c1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (c2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (c3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (norm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (conv_non_lin): ReLU()\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (l1): Linear(in_features=12800, out_features=512, bias=True)\n",
       "  (l2): Linear(in_features=512, out_features=124, bias=True)\n",
       "  (projection): Linear(in_features=124, out_features=10, bias=True)\n",
       "  (non_lin): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_task_1.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pLRWysggSq9"
   },
   "source": [
    "Локальные тесты для проверки вашей модели доступны ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_qMQzo1ggSq9",
    "outputId": "c00008eb-ef88-4000-ce47-e8dedd26e061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything seems fine!\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
    "\n",
    "try:\n",
    "    x = random_batch[0].to(device)\n",
    "    y = random_batch[1].to(device)\n",
    "\n",
    "    # compute outputs given inputs, both are variables\n",
    "    y_predicted = model_task_1(x)\n",
    "except Exception as e:\n",
    "    print(\"Something is wrong with the model\")\n",
    "    raise e\n",
    "\n",
    "\n",
    "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
    "\n",
    "print(\"Everything seems fine!\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suRmIPwIgSq9"
   },
   "source": [
    "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "YJnU14bdnZa_"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_task_1.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=10)\n",
    "num_epochs = 5\n",
    "best_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Mean Train Loss: 0.4035229434291522\n",
      "Mean Test Loss: 0.3177918307721234\n",
      "Neural network accuracy on test set: 0.8855\n",
      "New model saved.\n",
      "\n",
      "Epoch: 2\n",
      "Mean Train Loss: 0.2930499559481939\n",
      "Mean Test Loss: 0.2872174430412416\n",
      "Neural network accuracy on test set: 0.895\n",
      "New model saved.\n",
      "\n",
      "Epoch: 3\n",
      "Mean Train Loss: 0.2534048444330692\n",
      "Mean Test Loss: 0.2696300525777637\n",
      "Neural network accuracy on test set: 0.8991\n",
      "New model saved.\n",
      "\n",
      "Epoch: 4\n",
      "Mean Train Loss: 0.23045431707998118\n",
      "Mean Test Loss: 0.26651847011412677\n",
      "Neural network accuracy on test set: 0.9054\n",
      "New model saved.\n",
      "\n",
      "Epoch: 5\n",
      "Mean Train Loss: 0.214177672226727\n",
      "Mean Test Loss: 0.24786797162895194\n",
      "Neural network accuracy on test set: 0.9141\n",
      "New model saved.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch: {epoch + 1}')\n",
    "    model_task_1.train()\n",
    "    train_loss_history = []\n",
    "    for x_batch, y_batch in train_data_loader:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model_task_1(x_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        train_loss_history.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Mean Train Loss: {np.mean(train_loss_history)}')\n",
    "\n",
    "    model_task_1.eval()\n",
    "    test_loss_history = []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_data_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            y_pred = model_task_1(x_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            test_loss_history.append(loss.item())\n",
    "    print(f'Mean Test Loss: {np.mean(test_loss_history)}')\n",
    "    \n",
    "    test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
    "    scheduler.step(test_acc_task_1)\n",
    "    print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")\n",
    "    \n",
    "    if test_acc_task_1 > best_score:\n",
    "        best_score = test_acc_task_1\n",
    "        torch.save(model_task_1, 'best_model.pth')\n",
    "        print('New model saved.')\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pasha\\AppData\\Local\\Temp\\ipykernel_33624\\1070498729.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_task_1 = torch.load('best_model.pth')\n"
     ]
    }
   ],
   "source": [
    "model_task_1 = torch.load('best_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zce7gt1gSq-"
   },
   "source": [
    "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usswrWYOgSq-"
   },
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Xua3TVZHgSq-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.93732\n"
     ]
    }
   ],
   "source": [
    "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
    "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "l9KEKXBxgSq-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.9141\n"
     ]
    }
   ],
   "source": [
    "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
    "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oyhmMobgSq_"
   },
   "source": [
    "Проверка, что необходимые пороги пройдены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "OAIrURCEgSq_",
    "outputId": "7c983690-a92e-4693-89fb-7c86c002921a"
   },
   "outputs": [],
   "source": [
    "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
    "assert (\n",
    "    train_acc_task_1 >= 0.905\n",
    "), \"Test accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to `submission_dict_task_1.json`\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_overfitting_data_dict.npy\"\n",
    "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
    "\n",
    "submission_dict = {\n",
    "    \"train_predictions_task_1\": get_predictions(\n",
    "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
    "    ),\n",
    "    \"test_predictions_task_1\": get_predictions(\n",
    "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
    "    ),\n",
    "    \"model_task_1\": parse_pytorch_model(str(model_task_1)),\n",
    "}\n",
    "\n",
    "with open(\"submission_dict_task_1.json\", \"w\") as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print(\"File saved to `submission_dict_task_1.json`\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача №2: Переобучение (Initiation)\n",
    "Продолжим работу с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). Теперь ваша задача продемонстрировать переобучение модели на обучающей выборке. Достаточно показать, что точность классификации (не только функция потерь!) на тестовой выборке значительно отстает от обучающей.\n",
    "\n",
    "Обращаем ваше внимание, в задаче №3 вам придется починить данную модель (минимизировать эффект переобучения) с помощью механизмов регуляризации, поэтому не переусердствуйте!\n",
    "\n",
    "__Ваша вторая задача: реализовать используя пайплан обучения модели продемонстрировать переобучения модели на обучающей выборке.__\n",
    "\n",
    "Код для обучения модели вы можете переиспользовать. Далее присутствует лишь несколько тестов, которые помогут вам проверить свое решение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимание, вам необходимо использовать переменную `model_task_2` для хранение модели во второй задаче. \n",
    "\n",
    "Не используйте `Dropout` и `BatchNorm` в этой задаче"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model instance\n",
    "model_task_2 = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 64, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "\n",
    "    nn.Linear(64 * 22 * 22, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (3): ReLU()\n",
       "  (4): Flatten(start_dim=1, end_dim=-1)\n",
       "  (5): Linear(in_features=30976, out_features=512, bias=True)\n",
       "  (6): Tanh()\n",
       "  (7): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_task_2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_task_2.parameters(), lr=0.001)\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Mean Train Loss: 0.380611911213398\n",
      "Mean Test Loss: 0.3177601790394836\n",
      "Neural network accuracy on test set: 0.8804\n",
      "\n",
      "Epoch: 2\n",
      "Mean Train Loss: 0.2396388054281473\n",
      "Mean Test Loss: 0.2668157075278866\n",
      "Neural network accuracy on test set: 0.904\n",
      "\n",
      "Epoch: 3\n",
      "Mean Train Loss: 0.17085671893432736\n",
      "Mean Test Loss: 0.2667161749538998\n",
      "Neural network accuracy on test set: 0.9112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch: {epoch + 1}')\n",
    "    model_task_2.train()\n",
    "    train_loss_history = []\n",
    "    for x_batch, y_batch in train_data_loader:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model_task_2(x_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        train_loss_history.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Mean Train Loss: {np.mean(train_loss_history)}')\n",
    "\n",
    "    model_task_2.eval()\n",
    "    test_loss_history = []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_data_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            y_pred = model_task_2(x_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            test_loss_history.append(loss.item())\n",
    "    print(f'Mean Test Loss: {np.mean(test_loss_history)}')\n",
    "    \n",
    "    test_acc_task_1 = get_accuracy(model_task_2, test_data_loader)\n",
    "    print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка архитектуры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "layers_task_2 = []\n",
    "for element in parse_pytorch_model(str(model_task_2)).get(\"layers\", []):\n",
    "    layer_name = element[\"layer\"][\"type\"]\n",
    "    assert \"dropout\" not in layer_name.lower(), \"Do not use Dropout in Task 2!\"\n",
    "    assert \"batchnorm\" not in layer_name.lower(), \"Do not use BatchNorm in Task 2!\"\n",
    "    layers_task_2.append(layer_name)\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.96033\n"
     ]
    }
   ],
   "source": [
    "train_acc_task_2 = get_accuracy(model_task_2, train_data_loader)\n",
    "print(f\"Neural network accuracy on train set: {train_acc_task_2:3.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.9112\n"
     ]
    }
   ],
   "source": [
    "test_acc_task_2 = get_accuracy(model_task_2, test_data_loader)\n",
    "print(f\"Neural network accuracy on test set: {test_acc_task_2:3.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка, что переобучение присутствует:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_acc_task_2 >= test_acc_task_2, \"Train accuracy must be higher than task accuracy\"\n",
    "assert train_acc_task_2 >= 0.88, \"Train accuracy must be higher than 0.88\"\n",
    "assert (\n",
    "    train_acc_task_2 - test_acc_task_2 >= 0.04\n",
    "), \"Test accuracy should be at least 0.04 lower that train.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_2`.\n",
    "\n",
    "Также предполагается, что в переменной `submission_dict` уже содержатся результаты задачи №1. Если их там нет, загрузите их из сохраненного файла в переменную перед запуском следующей ячейки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to `submission_dict_tasks_1_and_2.json`\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_overfitting_data_dict.npy\"\n",
    "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
    "\n",
    "submission_dict.update(\n",
    "    {\n",
    "        \"train_predictions_task_2\": get_predictions(\n",
    "            model_task_2, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
    "        ),\n",
    "        \"test_predictions_task_2\": get_predictions(\n",
    "            model_task_2, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
    "        ),\n",
    "        \"model_task_2\": parse_pytorch_model(str(model_task_2)),\n",
    "    }\n",
    ")\n",
    "\n",
    "with open(\"submission_dict_tasks_1_and_2.json\", \"w\") as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print(\"File saved to `submission_dict_tasks_1_and_2.json`\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача №3: Исправление модели (Return) \n",
    "Все так же работаем с [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). Наконец, ваша задача исправить ~~ошибки прошлого~~ переобучение модели, построенной в задаче 2. Достаточно добиться расхождения между точностью классификации на обучающей и тестовой выборках не превышающего 0.015 (т.е. полутора процентов).\n",
    "\n",
    "Обращаем ваше внимание, архитектура модели в задаче №3 не должна существенно отличаться от задачи №2! Вы можете использовать Batchnorm, Dropout, уменьшить размерность промежуточных представлений, обратиться к аугментации данных, но вы не можете использовать меньшее количество слоёв.\n",
    "\n",
    "__Ваша третья и финальная задача: исправить модель и/или процесс обучения, дабы справиться с переобучением.__\n",
    "\n",
    "Код для обучения модели вы можете переиспользовать. Далее присутствует лишь несколько тестов, которые помогут вам проверить свое решение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимание, вам необходимо использовать переменную `model_task_3` для хранение модели во второй задаче. \n",
    "\n",
    "Также код ниже будет обращаться к переменной `layers_task_2`, инициализируйте её, если она не определена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert (\n",
    "    layers_task_2 is not None\n",
    "), \"Initializa layers_task_2 vairable which contains list of layers in task 2 model\"\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_task_3 = nn.Sequential(\n",
    "    nn.Conv2d(1, 4, 5),\n",
    "    nn.BatchNorm2d(4),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(4, 8, 3),\n",
    "    nn.BatchNorm2d(8),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(8 * 22 * 22, 512),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       "  (3): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU()\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Dropout(p=0.5, inplace=False)\n",
       "  (8): Linear(in_features=3872, out_features=512, bias=True)\n",
       "  (9): Dropout(p=0.5, inplace=False)\n",
       "  (10): Tanh()\n",
       "  (11): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_task_3.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_task_3.parameters(), lr=0.001)\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Mean Train Loss: 0.5251652861992518\n",
      "Mean Test Loss: 0.592376118490157\n",
      "Neural network accuracy on test set: 0.8375\n",
      "\n",
      "Epoch: 2\n",
      "Mean Train Loss: 0.4186920064528783\n",
      "Mean Test Loss: 0.4726307620339024\n",
      "Neural network accuracy on test set: 0.8653\n",
      "\n",
      "Epoch: 3\n",
      "Mean Train Loss: 0.3855187549849351\n",
      "Mean Test Loss: 0.4688666459268179\n",
      "Neural network accuracy on test set: 0.8737\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch: {epoch + 1}')\n",
    "    model_task_3.train()\n",
    "    train_loss_history = []\n",
    "    for x_batch, y_batch in train_data_loader:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model_task_3(x_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        train_loss_history.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Mean Train Loss: {np.mean(train_loss_history)}')\n",
    "\n",
    "    model_task_3.eval()\n",
    "    test_loss_history = []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_data_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            y_pred = model_task_3(x_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            test_loss_history.append(loss.item())\n",
    "    print(f'Mean Test Loss: {np.mean(test_loss_history)}')\n",
    "    \n",
    "    test_acc_task_1 = get_accuracy(model_task_3, test_data_loader)\n",
    "    print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка архитектуры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "layers_task_3 = []\n",
    "for element in parse_pytorch_model(str(model_task_3)).get(\"layers\", []):\n",
    "    layer_name = element[\"layer\"][\"type\"]\n",
    "    layers_task_3.append(layer_name)\n",
    "\n",
    "\n",
    "idx = 0\n",
    "for model_3_layer in layers_task_3:\n",
    "    model_2_layer = layers_task_2[idx]\n",
    "    if \"dropout\" not in model_3_layer.lower() and \"batchnorm\" not in model_3_layer.lower():\n",
    "        assert (\n",
    "            model_3_layer == model_2_layer\n",
    "        ), \"Models in tasks 2 and 3 must share the architecture except for Dropout and BatchNorm!\"\n",
    "        idx += 1\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.88725\n"
     ]
    }
   ],
   "source": [
    "train_acc_task_3 = get_accuracy(model_task_3, train_data_loader)\n",
    "print(f\"Neural network accuracy on train set: {train_acc_task_3:3.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.8737\n"
     ]
    }
   ],
   "source": [
    "test_acc_task_3 = get_accuracy(model_task_3, test_data_loader)\n",
    "print(f\"Neural network accuracy on test set: {test_acc_task_3:3.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка, что переобучение присутствует:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_acc_task_3 >= 0.88, \"Train accuracy must be higher than 0.88\"\n",
    "assert train_acc_task_3 >= 0.865, \"Test accuracy must be higher than 0.865\"\n",
    "assert (\n",
    "    train_acc_task_3 - test_acc_task_3 <= 0.015\n",
    "), \"Test accuracy should not be lower that train more than by 0.015\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_3`.\n",
    "\n",
    "Также предполагается, что в переменной `submission_dict` уже содержатся результаты задач №1 и №2. Если их там нет, загрузите их из сохраненных файлов перед запуском следующей ячейки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to `submission_dict_final.json`\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_overfitting_data_dict.npy\"\n",
    "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
    "\n",
    "submission_dict.update(\n",
    "    {\n",
    "        \"train_predictions_task_3\": get_predictions(\n",
    "            model_task_3, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
    "        ),\n",
    "        \"test_predictions_task_3\": get_predictions(\n",
    "            model_task_3, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
    "        ),\n",
    "        \"model_task_3\": parse_pytorch_model(str(model_task_3)),\n",
    "    }\n",
    ")\n",
    "\n",
    "with open(\"submission_dict_final.json\", \"w\") as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print(\"File saved to `submission_dict_final.json`\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xai8JL3tgSq_"
   },
   "source": [
    "### Сдача задания\n",
    "Сдайте сгенерированные файлы в соответствующие задачи в соревновании, а именно:\n",
    "* `submission_dict_tasks_1_and_2.json` в задачу Initiation\n",
    "* `submission_dict_final.json` в задачу Return.\n",
    "\n",
    "\n",
    "`submission_dict_task_1.json` сдавать не нужно, он уже был сдан ранее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtWnYAN_gSrA"
   },
   "source": [
    "На этом задание завершено. Поздравляем!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".cv_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
