{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9126852-2a02-4a6c-b252-173e8bc08f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e198d5f2-f616-486e-bcdd-5cd9f411d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConv(nn.Module):\n",
    "    def __init__(self, kernel_size: int = 1):\n",
    "        super(MyConv, self).__init__()\n",
    "        self.kernel = nn.Parameter(torch.tensor(torch.rand(kernel_size, kernel_size), dtype = torch.float32).unsqueeze(0).unsqueeze(0))\n",
    "        \n",
    "    def forward(self, picture):\n",
    "        # look at dims of input\n",
    "        batch_size, n_channels, height, width = picture.size()\n",
    "        k_height, k_width = self.kernel.size(2), self.kernel.size(3)\n",
    "\n",
    "        #output size\n",
    "        o_height, o_width = height - k_height + 1, width - k_width + 1\n",
    "        \n",
    "        #initilize output\n",
    "        output = torch.tensor(torch.rand(o_height, o_width)).unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        #perform convolution\n",
    "        for i in range(o_height):\n",
    "            for j in range(o_width):\n",
    "                elem = torch.sum(picture[:, :, i:i+k_height, j:j+k_width] * self.kernel)\n",
    "                output[:, :, i, j] = elem\n",
    "        return output        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c43546ec-45ea-413c-b0bd-a02ae88e9d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.9104, 0.5981],\n",
       "          [0.7515, 0.3823]]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(2, 2).unsqueeze(0).unsqueeze(0)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3160a0c7-93d8-473f-b2a1-f7f90054198a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.5142]]]], grad_fn=<AsStridedBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[[[0.8601, 0.4645],\n",
      "          [0.2049, 0.7832]]]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pasha\\AppData\\Local\\Temp\\ipykernel_28892\\4275808789.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.kernel = nn.Parameter(torch.tensor(torch.rand(kernel_size, kernel_size), dtype = torch.float32).unsqueeze(0).unsqueeze(0))\n",
      "C:\\Users\\pasha\\AppData\\Local\\Temp\\ipykernel_28892\\4275808789.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output = torch.tensor(torch.rand(o_height, o_width)).unsqueeze(0).unsqueeze(0)\n"
     ]
    }
   ],
   "source": [
    "cnn = MyConv(kernel_size=2)\n",
    "outp = cnn.forward(a)\n",
    "print(outp)\n",
    "print(cnn.kernel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
