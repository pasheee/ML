{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bc1e566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from itertools import permutations\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "DATA_PATH = './data'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "900f5976",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_df = pd.read_csv(os.path.join(DATA_PATH, 'algos.csv'), header=None)\n",
    "f1 = torch.tensor(filters_df.iloc[0].values.reshape(3, 3), dtype=torch.float32, device=device)\n",
    "f2 = torch.tensor(filters_df.iloc[1].values.reshape(3, 3), dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0854ff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "class ImageWithTxtDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform or transforms.ToTensor()\n",
    "        self.files = [f for f in os.listdir(data_dir) if f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.files[idx]\n",
    "        img_path = os.path.join(self.data_dir, img_name)\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        image = self.transform(image)  \n",
    "\n",
    "        txt_name = img_name.replace('.png', '.txt')\n",
    "        txt_path = os.path.join(self.data_dir, txt_name)\n",
    "        label = pd.read_csv(txt_path, header=None, sep=' ').values\n",
    "        label = torch.tensor(label, dtype=torch.float32).unsqueeze(0) \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45c37015",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageWithTxtDataset(DATA_PATH, transform)\n",
    "loader = DataLoader(dataset, batch_size=len(dataset), shuffle=False)\n",
    "X_batch_cpu, Y_batch_cpu = next(iter(loader))\n",
    "X_batch_cpu *= 256\n",
    "\n",
    "dtype = torch.float32\n",
    "X_batch = X_batch_cpu.to(device=device, dtype=dtype)\n",
    "Y_batch = Y_batch_cpu.to(device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f23a5bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_w = f1.unsqueeze(0).unsqueeze(0)  \n",
    "f2_w = f2.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "results = []\n",
    "labels = ['f1', 'f2', 'f_unknown']\n",
    "perm = ['f2', 'f_unknown', 'f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "594d6dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perm ['f2', 'f_unknown', 'f1']:   1%|          | 79/10000 [00:00<00:27, 354.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss=4704.5068359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perm ['f2', 'f_unknown', 'f1']:  11%|█         | 1083/10000 [00:03<00:25, 350.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000, loss=0.0022613765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perm ['f2', 'f_unknown', 'f1']:  21%|██        | 2083/10000 [00:06<00:22, 345.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2000, loss=0.0008909916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perm ['f2', 'f_unknown', 'f1']:  31%|███       | 3087/10000 [00:09<00:20, 344.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3000, loss=0.0001824660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perm ['f2', 'f_unknown', 'f1']:  41%|████      | 4085/10000 [00:12<00:16, 354.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4000, loss=0.0000330281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perm ['f2', 'f_unknown', 'f1']:  51%|█████     | 5082/10000 [00:15<00:13, 359.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5000, loss=0.0000059003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perm ['f2', 'f_unknown', 'f1']:  61%|██████    | 6088/10000 [00:18<00:11, 345.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6000, loss=0.0000010449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perm ['f2', 'f_unknown', 'f1']:  71%|███████   | 7085/10000 [00:21<00:08, 349.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7000, loss=0.0000001900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perm ['f2', 'f_unknown', 'f1']:  81%|████████  | 8088/10000 [00:24<00:05, 345.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8000, loss=0.0000173136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perm ['f2', 'f_unknown', 'f1']:  91%|█████████ | 9086/10000 [00:27<00:02, 351.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9000, loss=0.0075473450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perm ['f2', 'f_unknown', 'f1']: 100%|██████████| 10000/10000 [00:30<00:00, 325.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation ['f2', 'f_unknown', 'f1'], loss=0.000000\n"
     ]
    }
   ],
   "source": [
    "unk = torch.full((1, 1, 3, 3), 0.0625, dtype=torch.float32, device=device, requires_grad=True)\n",
    "optimizer = torch.optim.Adam([unk], lr=0.1)\n",
    "\n",
    "for epoch in tqdm(range(10000), desc=f\"Perm {perm}\"):\n",
    "    optimizer.zero_grad()\n",
    "    cur = X_batch.clone()\n",
    "\n",
    "    for lbl in perm:\n",
    "        if lbl == 'f1':\n",
    "            cur = F.conv2d(cur, f1_w, bias=None, padding=1)\n",
    "        elif lbl == 'f2':\n",
    "            cur = F.conv2d(cur, f2_w, bias=None, padding=1)\n",
    "        else:\n",
    "            cur = F.conv2d(cur, unk, bias=None, padding=1)\n",
    "    loss = F.mse_loss(cur, Y_batch)\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch {epoch}, loss={loss.item():.10f}\")\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "results.append({'perm': perm, 'loss': loss.item(), 'filter': unk.detach().clone()})\n",
    "print(f\"Permutation {perm}, loss={loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06f77fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'perm': ['f2', 'f_unknown', 'f1'], 'loss': 3.4189044928467638e-09, 'filter': tensor([[[[0.1245, 0.2490, 0.1245],\n",
      "          [0.2490, 0.4980, 0.2490],\n",
      "          [0.1245, 0.2490, 0.1245]]]], device='cuda:0')}]\n"
     ]
    }
   ],
   "source": [
    "results = sorted(results, key=lambda x: x['loss'])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3b0bbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best perm: ['f2', 'f_unknown', 'f1'] with loss 0.000000003\n",
      "Saved reconstructed_algos.csv\n"
     ]
    }
   ],
   "source": [
    "best = results[0]\n",
    "print(f\"Best perm: {best['perm']} with loss {best['loss']:.9f}\")\n",
    "recon_filters = []\n",
    "for lbl in best['perm']:\n",
    "    if lbl == 'f1':\n",
    "        recon_filters.append(f1.cpu())\n",
    "    elif lbl == 'f2':\n",
    "        recon_filters.append(f2.cpu())\n",
    "    else:\n",
    "        rek = best['filter'].squeeze(0).squeeze(0).cpu()\n",
    "        recon_filters.append(rek)\n",
    "\n",
    "# Сохранение reconstructed_algos.csv\n",
    "recon_array = np.array([f.flatten().numpy() for f in recon_filters])\n",
    "recon_df = pd.DataFrame(recon_array)\n",
    "recon_df.to_csv('reconstructed_algos.csv', header=False, index=False)\n",
    "print('Saved reconstructed_algos.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ceeb59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".cv_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
