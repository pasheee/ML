{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDsVMGiVgSq2"
   },
   "source": [
    "## Классификация FashionMNIST\n",
    "\n",
    "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/girafe_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3isBRG6PgSq6"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "\n",
    "def parse_pytorch_model(model_str):\n",
    "    def parse_layer(layer_str):\n",
    "        layer_info = {}\n",
    "        layer_name, params = layer_str.split(\"(\", 1)\n",
    "        params = params.rstrip(\")\")\n",
    "        layer_info[\"type\"] = layer_name.strip()\n",
    "        param_dict = {}\n",
    "        for param in params.split(\", \"):\n",
    "            if \"=\" in param:\n",
    "                key, value = param.split(\"=\")\n",
    "                param_dict[key.strip()] = eval(value.strip())\n",
    "            else:\n",
    "                param_dict[param.strip()] = None\n",
    "        layer_info[\"parameters\"] = param_dict\n",
    "        return layer_info\n",
    "\n",
    "    model_dict = {}\n",
    "    lines = model_str.splitlines()\n",
    "    model_name = lines[0].strip(\"()\")\n",
    "    model_dict[\"model_name\"] = model_name\n",
    "    model_dict[\"layers\"] = []\n",
    "\n",
    "    layer_regex = re.compile(r\"\\((\\d+)\\): (.+)\")\n",
    "    for line in lines[1:]:\n",
    "        line = line.strip()\n",
    "        match = layer_regex.match(line)\n",
    "        if match:\n",
    "            index, layer = match.groups()\n",
    "            model_dict[\"layers\"].append({\"index\": int(index), \"layer\": parse_layer(layer)})\n",
    "    return model_dict\n",
    "\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "def get_predictions(model, eval_data, step=10):\n",
    "\n",
    "    predicted_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx in range(0, len(eval_data), step):\n",
    "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
    "\n",
    "    predicted_labels = torch.cat(predicted_labels)\n",
    "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
    "    return predicted_labels\n",
    "\n",
    "\n",
    "def get_accuracy(model, data_loader):\n",
    "    predicted_labels = []\n",
    "    real_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            y_predicted = model(batch[0].to(device))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
    "            real_labels.append(batch[1])\n",
    "\n",
    "    predicted_labels = torch.cat(predicted_labels)\n",
    "    real_labels = torch.cat(real_labels)\n",
    "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
    "    return accuracy_score\n",
    "\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_fmnist_data_dict.npy\"\n",
    "), \"Please, download `hw_fmnist_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zeA6Q5-CgSq7"
   },
   "source": [
    "Вернемся к задаче распознавания простых изображений, рассмотренной ранее. Но теперь будем работать с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). В данном задании воспользуемся всем датасетом целиком.\n",
    "\n",
    "__Ваша первая задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n",
    "\n",
    "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбукам с предыдущих занятий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_DEVICE_ID = 0  # change if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nPG1KbQAgl8b"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "device = (\n",
    "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    ")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "id": "aYcL28OsgSq8",
    "outputId": "93aafa07-fb56-43bd-f928-918f45fe30e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Image label: 0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "train_fmnist_data = FashionMNIST(\n",
    "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "test_fmnist_data = FashionMNIST(\n",
    "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_fmnist_data, batch_size=1024, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_fmnist_data, batch_size=1024, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "random_batch = next(iter(train_data_loader))\n",
    "_image, _label = random_batch[0][0], random_batch[1][0]\n",
    "plt.figure()\n",
    "plt.imshow(_image.reshape(28, 28))\n",
    "plt.title(f\"Image label: {_label}\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6jWRv1rgSq8"
   },
   "source": [
    "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
    "\n",
    "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CV_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Convolution blocks:\n",
    "        self.c1 = nn.Conv2d(1, 32, 5)\n",
    "        self.norm1 = nn.BatchNorm2d(32)\n",
    "        self.c2 = nn.Conv2d(32, 64, 3)\n",
    "        self.norm2 = nn.BatchNorm2d(64)\n",
    "        self.c3 = nn.Conv2d(64, 128, 3)\n",
    "        self.norm3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.pooling = nn.MaxPool2d(2)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "        self.conv_non_lin = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Linear Blocks:\n",
    "        self.l1 = nn.Linear(128 * 5 * 5, 512)\n",
    "        self.l2 = nn.Linear(512, 124)\n",
    "        self.projection = nn.Linear(124, 10)\n",
    "        self.non_lin = nn.Tanh()\n",
    "\n",
    "    def forward(self, X):\n",
    "        conv_out = self.conv_non_lin( self.norm2( self.pooling( self.c2( self.norm1( self.conv_non_lin(self.c1(X)) ) ) ) ) )\n",
    "        conv_out = self.conv_non_lin( self.pooling( self.c3(conv_out) ) )\n",
    "        flattened_conv_out = self.flatten(conv_out)\n",
    "\n",
    "        return self.projection( self.non_lin( self.l2( self.non_lin(self.dropout(self.l1(flattened_conv_out))) ) ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "BcyEFX-RgSq8"
   },
   "outputs": [],
   "source": [
    "# Creating model instance\n",
    "model_task_1 = CV_Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAoLV4dkoy5M"
   },
   "source": [
    "Не забудьте перенести модель на выбранный `device`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Xas9SIXDoxvZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CV_Model(\n",
       "  (c1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (c2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (c3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (norm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv_non_lin): ReLU()\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (l1): Linear(in_features=3200, out_features=512, bias=True)\n",
       "  (l2): Linear(in_features=512, out_features=124, bias=True)\n",
       "  (projection): Linear(in_features=124, out_features=10, bias=True)\n",
       "  (non_lin): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_task_1.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pLRWysggSq9"
   },
   "source": [
    "Локальные тесты для проверки вашей модели доступны ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_qMQzo1ggSq9",
    "outputId": "c00008eb-ef88-4000-ce47-e8dedd26e061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything seems fine!\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
    "\n",
    "try:\n",
    "    x = random_batch[0].to(device)\n",
    "    y = random_batch[1].to(device)\n",
    "\n",
    "    # compute outputs given inputs, both are variables\n",
    "    y_predicted = model_task_1(x)\n",
    "except Exception as e:\n",
    "    print(\"Something is wrong with the model\")\n",
    "    raise e\n",
    "\n",
    "\n",
    "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
    "\n",
    "print(\"Everything seems fine!\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suRmIPwIgSq9"
   },
   "source": [
    "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_task_1.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=10)\n",
    "num_epochs = 15\n",
    "best_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(10):\n",
    "#     print(f'Epoch: {epoch}')\n",
    "#     model_task_1.train()\n",
    "#     train_loss_history = []\n",
    "#     for x_batch, y_batch in train_data_loader:\n",
    "#         x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         y_pred = model_task_1(x_batch)\n",
    "#         loss = criterion(y_pred, y_batch)\n",
    "#         train_loss_history.append(loss.item())\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     print(f'Mean Train Loss: {np.mean(train_loss_history)}')\n",
    "\n",
    "#     test_loss_history = []\n",
    "#     for x_batch, y_batch in test_data_loader:\n",
    "#         x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         y_pred = model_task_1(x_batch)\n",
    "#         loss = criterion(y_pred, y_batch)\n",
    "#         test_loss_history.append(loss.item())\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     print(f'Mean Test Loss: {np.mean(test_loss_history)}')\n",
    "    \n",
    "#     test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
    "#     scheduler.step(test_acc_task_1)\n",
    "#     print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")\n",
    "    \n",
    "#     if test_acc_task_1 > best_score:\n",
    "#         best_score = test_acc_task_1\n",
    "#         torch.save(model_task_1, 'best_model.pth')\n",
    "#         print('New model saved.')\n",
    "\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "YJnU14bdnZa_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Mean Train Loss: 0.6250517701698561\n",
      "Mean Test Loss: 0.39575985372066497\n",
      "Neural network accuracy on test set: 0.8574\n",
      "New model saved.\n",
      "\n",
      "Epoch: 2\n",
      "Mean Train Loss: 0.30706890887123045\n",
      "Mean Test Loss: 0.30462942123413084\n",
      "Neural network accuracy on test set: 0.8865\n",
      "New model saved.\n",
      "\n",
      "Epoch: 3\n",
      "Mean Train Loss: 0.244761656148959\n",
      "Mean Test Loss: 0.2567975789308548\n",
      "Neural network accuracy on test set: 0.9095\n",
      "New model saved.\n",
      "\n",
      "Epoch: 4\n",
      "Mean Train Loss: 0.19746471587884223\n",
      "Mean Test Loss: 0.23353313207626342\n",
      "Neural network accuracy on test set: 0.9159\n",
      "New model saved.\n",
      "\n",
      "Epoch: 5\n",
      "Mean Train Loss: 0.1711196230124619\n",
      "Mean Test Loss: 0.2265644058585167\n",
      "Neural network accuracy on test set: 0.9166\n",
      "New model saved.\n",
      "\n",
      "Epoch: 6\n",
      "Mean Train Loss: 0.1435653847658028\n",
      "Mean Test Loss: 0.235422021150589\n",
      "Neural network accuracy on test set: 0.9169\n",
      "New model saved.\n",
      "\n",
      "Epoch: 7\n",
      "Mean Train Loss: 0.11665792056059433\n",
      "Mean Test Loss: 0.21382314711809158\n",
      "Neural network accuracy on test set: 0.9237\n",
      "New model saved.\n",
      "\n",
      "Epoch: 8\n",
      "Mean Train Loss: 0.09976649044428841\n",
      "Mean Test Loss: 0.22379011064767837\n",
      "Neural network accuracy on test set: 0.9249\n",
      "New model saved.\n",
      "\n",
      "Epoch: 9\n",
      "Mean Train Loss: 0.08129405432333381\n",
      "Mean Test Loss: 0.24311960339546204\n",
      "Neural network accuracy on test set: 0.9221\n",
      "\n",
      "Epoch: 10\n",
      "Mean Train Loss: 0.07095543648731911\n",
      "Mean Test Loss: 0.24333298206329346\n",
      "Neural network accuracy on test set: 0.9255\n",
      "New model saved.\n",
      "\n",
      "Epoch: 11\n",
      "Mean Train Loss: 0.04954281073631877\n",
      "Mean Test Loss: 0.2564582467079163\n",
      "Neural network accuracy on test set: 0.9229\n",
      "\n",
      "Epoch: 12\n",
      "Mean Train Loss: 0.03863311401110584\n",
      "Mean Test Loss: 0.2657469630241394\n",
      "Neural network accuracy on test set: 0.9246\n",
      "\n",
      "Epoch: 13\n",
      "Mean Train Loss: 0.03460665170292733\n",
      "Mean Test Loss: 0.2718142464756966\n",
      "Neural network accuracy on test set: 0.9247\n",
      "\n",
      "Epoch: 14\n",
      "Mean Train Loss: 0.022127707741396913\n",
      "Mean Test Loss: 0.28131777197122576\n",
      "Neural network accuracy on test set: 0.9278\n",
      "New model saved.\n",
      "\n",
      "Epoch: 15\n",
      "Mean Train Loss: 0.016918419544600834\n",
      "Mean Test Loss: 0.29961086213588717\n",
      "Neural network accuracy on test set: 0.9207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch: {epoch + 1}')\n",
    "    model_task_1.train()\n",
    "    train_loss_history = []\n",
    "    for x_batch, y_batch in train_data_loader:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model_task_1(x_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        train_loss_history.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Mean Train Loss: {np.mean(train_loss_history)}')\n",
    "\n",
    "    model_task_1.eval()\n",
    "    test_loss_history = []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_data_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            y_pred = model_task_1(x_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            test_loss_history.append(loss.item())\n",
    "    print(f'Mean Test Loss: {np.mean(test_loss_history)}')\n",
    "    \n",
    "    test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
    "    scheduler.step(test_acc_task_1)\n",
    "    print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")\n",
    "    \n",
    "    if test_acc_task_1 > best_score:\n",
    "        best_score = test_acc_task_1\n",
    "        torch.save(model_task_1, 'best_model.pth')\n",
    "        print('New model saved.')\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_task_1 = torch.load('best_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zce7gt1gSq-"
   },
   "source": [
    "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usswrWYOgSq-"
   },
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xua3TVZHgSq-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.94662\n"
     ]
    }
   ],
   "source": [
    "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
    "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l9KEKXBxgSq-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.8981\n"
     ]
    }
   ],
   "source": [
    "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
    "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oyhmMobgSq_"
   },
   "source": [
    "Проверка, что необходимые пороги пройдены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "OAIrURCEgSq_",
    "outputId": "7c983690-a92e-4693-89fb-7c86c002921a"
   },
   "outputs": [],
   "source": [
    "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
    "assert (\n",
    "    train_acc_task_1 >= 0.905\n",
    "), \"Test accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`, а файл `hw_fmnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to `submission_dict_fmnist_task_1.json`\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_fmnist_data_dict.npy\"\n",
    "), \"Please, download `hw_fmnist_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "loaded_data_dict = np.load(\"hw_fmnist_data_dict.npy\", allow_pickle=True)\n",
    "\n",
    "submission_dict = {\n",
    "    \"train_predictions_task_1\": get_predictions(\n",
    "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
    "    ),\n",
    "    \"test_predictions_task_1\": get_predictions(\n",
    "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
    "    ),\n",
    "    \"model_task_1\": parse_pytorch_model(str(model_task_1)),\n",
    "}\n",
    "\n",
    "with open(\"submission_dict_fmnist_task_1.json\", \"w\") as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print(\"File saved to `submission_dict_fmnist_task_1.json`\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сдача задания\n",
    "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
    "    \n",
    "* `submission_dict_fmnist_task_1.json` в задачу Separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtWnYAN_gSrA"
   },
   "source": [
    "На этом задание завершено. Поздравляем!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".cv_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
